---
title: "La disrupción de la IA a las puertas de la escuela"
subtitle: ""
description: "¿Recordaremos este curso como un punto de inflexión?"
date: 2024-09-01T15:32:00+02:00
lastmod: 2024-09-01T15:32:00+02:00
draft: false

author: "davidlms"

# uBlogger NEW | 1.0.0 Article Update Information
upd: ""

# uBlogger NEW | 1.0.0 Author's comment, is shown above all comments
authorComment: ""

# uBlogger  | 1.2.0 article design theme
theme: ""
# uBlogger NEW | 1.2.0 Allows you to hide the preview image on the article page
hiddenFeaturedImage: false

# uBlogger  | 1.2.0 Post display settings on the page
summaryStyle:
    # uBlogger NEW | 1.1.0 Display previews on the page of posts
    hiddenImage: false
    # uBlogger NEW | 1.1.0 Allows you to hide the description
    hiddenDescription: false
    # uBlogger NEW | 1.1.0 Allows you to hide the title
    hiddenTitle: true
    tags:
      # uBlogger NEW | 1.1.0 One of the options for displaying tags
      theme: "image"
      # uBlogger NEW | 1.1.0 Text color
      color: "white"
      # uBlogger NEW | 1.1.0 Backing color
      background: "black"
      # uBlogger NEW | 1.1.0 Tag transparency
      transparency: 0.9
tags: ['reflexión', 'inteligencia artificial']
categories: ['Reflexiones educativas']
resources:
- name: "featured-image"
  src: "featured-image.jpg"

hiddenFromHomePage: false
hiddenFromSearch: false
twemoji: false

ruby: true
fraction: true
fontawesome: true
linkToMarkdown: true
rssFullText: false

toc:
  enable: false
  auto: true
code:
  copy: true
  # ...
math:
  enable: true
  # ...
mapbox:
  accessToken: ""
  # ...
share:
  enable: true
  # ...
comment:
  enable: true
  # ...
library:
  css:
    # someCSS = "some.css"
    # located in "assets/"
    # Or
    # someCSS = "https://cdn.example.com/some.css"
  js:
    # someJS = "some.js"
    # located in "assets/"
    # Or
    # someJS = "https://cdn.example.com/some.js"
seo:
  images: []
  # ...
---
Parece mentira que **haya pasado un año** desde la última vez que escribí un nuevo artículo. Y, sin embargo, así es.

La verdad es que no me gusta nada volver escribiendo sobre el mismo tema que la última vez. La Inteligencia Artificial casi ha monopolizado nuestro contexto, y no me hace gracia que **monopolice también este espacio personal**. Pero al mismo tiempo, siento la necesidad de hablar de ello, ya que tengo la convicción de que la reflexión sobre los usos de esta tecnología es **urgente e imprescindible**. Una obligación moral como sociedad, y por lo tanto, elevada a la siguiente potencia para el colectivo docente. Si tú, querido/a lector/a has llegado hasta aquí y te encuentras absolutamente asqueado/a por tener que volver a leer sobre este tema, te pido disculpas y te animo a seguir tu camino por otros enlaces. No creo que escriba nada interesante de todas formas.

La verdad es que **no creo en las predicciones**. Hoy en día, con tantos factores a tener en cuenta, cualquier persona que te intente convencer de que va a pasar algo en concreto, probablemente esté estafándote de alguna forma. Aunque solo sea para que le sigas prestando tu atención. Así que esto tómalo solamente como una opinión: estamos a las puertas de una **revolución educativa** muy bestia. Mucho más radical y rápida que lo que supuso la aparición de Internet. Las señales están ahí para quien se pare a observarlas. No sé cómo terminará, ni siquiera si lo hará, hay demasiados procesos en paralelo avanzando sin detenerse, así que el número de ramificaciones posibles son infinitas. Pero sí creo firmemente que necesitamos armarnos para enfrentarla. Y el **conocimiento** es, como siempre, **nuestra mejor arma**.

Cuando las personas recibimos nuestro primer ordenador personal, teléfono móvil o smartphone, **no necesitamos conocer cómo funcionaban**. Solamente tuvimos que aprender a utilizarlos. Pero para ello no era necesario saber cómo se gestionaba internamente la memoria RAM o que había un procesador encargado de convertir todas nuestras acciones y sus respuestas en operaciones matemáticas simples. En cambio, para hacer un uso responsable de un LLM (gran modelo de lenguaje) no basta con saber abrir una página web y comenzar a escribir. ¿Puedes hacerlo? Puedes. Pero **puede ser peligroso**. No peligroso en el sentido Terminator. Peligroso porque podemos caer en dos trampas habituales con la misma probabilidad: **subestimar** sus capacidades... Y **sobreestimarlas**. Si las subestimamos, creeremos que no sirve para nada útil, no nos preocuparemos por su impacto. Y nos despistaremos... Hasta que un día no nos de tiempo a nadar y nos pille la ola. Si las sobreestimamos, nos fiaremos en exceso de sus respuestas. En poco tiempo dejaremos de revisarlas. Y nos convertiremos en personas irrelevantes. Antes de darnos cuenta, habremos perdido todo el sentido crítico. Como una persona que se pasa un año completo sin hacer nada de ejercicio, la rehabilitación será dura. Incluso **irreparable en algunos casos**. ¿Cómo sé que una amplia mayoría no comprende cómo funciona un modelo de lenguaje? Porque recientemente se hizo viral una pregunta mal contestada que está siendo utilizada para evaluar "lo poco inteligente" que son este tipo de modelos. Si conoces cómo funcionan, la sola realización de la pregunta te parece **totalmente absurda**, ya que no da lugar a ningún tipo de discusión ni conclusión. Así que ponte a prueba: ¿Sabrías explicar [esta respuesta de ChatGPT](https://chatgpt.com/share/65bf7312-2f8e-45a2-a2ba-f75dd88b262e) y por qué no tiene ningún tipo de sentido plantear esa pregunta a estos modelos? Si piensas que no, te aconsejo consultar [este artículo](https://ig.ft.com/generative-ai/). Si además buscas un recurso más técnico, [este vídeo](https://www.youtube.com/watch?v=zjkBMFhNj_g) es puro oro. No es posible enfrentarse a este, nuestro mayor aliado o nuestro peor enemigo, sin conocerlo.

Porque un LLM puede ser la herramienta **más útil** jamás inventada para el aprendizaje y, al mismo tiempo, la **mayor barrera** que nos hemos encontrado. Esta es la paradoja a la que nos enfrentamos. La desventaja de la que partimos, es que el aprendizaje requiere un esfuerzo consciente. Nuestros cerebros está optimizados para minimizar ese esfuerzo, y esta tecnología también permite puentearlo, dándonos un resultado válido (o incluso que parezca serlo simplemente), evitando esa desagradable sensación de retorcimiento de los sesos. Han sido **varios experimentos** en los que se han creado diferentes grupos para llevar a cabo ciertas tareas. Normalmente hay un grupo que no tiene acceso a ningún LLM, otro que tiene acceso a un LLM tipo GPT-3 y un tercer grupo con acceso a GPT-4. Las conclusiones de estos estudios suelen ser similares, ya que la velocidad con la que se completan tareas aumentan cuando se tiene acceso a un LLM. Cuanto más potente, mejor. Hay que destacar que en muchas ocasiones ha ocurrido que, el grupo con acceso al LLM más potente, ha terminado la tarea antes. Pero con errores. Porque es habitual sobreestimar sus capacidades y dejar de revisar si la respuesta es correcta o no. Más preocupante es el ámbito educativo. En lo que respecta a usar un LLM para el aprendizaje, normalmente el grupo con acceso al LLM más potente olvida más rápidamente. Aprende menos... O nada. De nuevo, **el aprendizaje requiere esfuerzo**. Y que las cosas se hagan con el menor esfuerzo posible, es un caramelito que solo las mentes más concienciadas evitarán masticar.

Durante este verano, he leído un par de libros sobre el tema que me han hecho **reflexionar** acerca de la aplicación de Inteligencia Artificial en educación: "Co-Intelligence: Living and Working with AI" de Ethan Mollick y "Brave New Words: How AI Will Revolutionize Education (and Why That's a Good Thing)" de Salman Khan. En el primero puedes encontrar una reflexión mucho mejor desarrollada de algunas ideas del párrafo anterior. El segundo, aunque en muchas ocasiones queda claro que es un panfleto publicitario de un producto, te permite hacerte una idea muy clara del **impacto positivo** que puede tener un modelo de lenguaje bien dirigido en el proceso de enseñanza-aprendizaje. Khan y su equipo tuvieron el privilegio de acceder a un modelo como GPT-4 varios meses antes de que se hiciera pública su existencia. Es interesante leer cómo se dieron cuenta del potencial destructivo que podía tener esta tecnología sobre su propio negocio, y cómo lograron **convertir ese peligro en una ventaja competitiva** como es [Khanmigo](https://www.khanmigo.ai). Disponible gratuitamente para todos los docentes en Estados Unidos. Algún día hablaré sobre cómo puede impactar en un mundo globalizado y competitivo que ciertas áreas geográficas tengan acceso a determinadas herramientas de forma exclusiva.

A mediados de curso, me topé con [este artículo](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/), que me hizo reflexionar sobre cómo la tecnología de un LLM puede combinarse, con diferentes llamadas y capacidades, para crear determinados "**sistemas complejos**" o "flujos de trabajo", como queramos llamarlos. El caso es que permiten automatizar ciertas funcionalidades que hasta ahora eran impensables llevar a cabo sin la intervención humana. Compensando, además, **ciertas limitaciones** de los modelos de lenguaje actuales. ¿Qué pasa si hacemos que un LLM reflexione sobre la idoneidad de su propia respuesta y elabore una nueva teniendo en cuenta esa crítica? Estos modelos también se equivocan al escribir código de programación pero... ¿Qué ocurre si le permito ejecutar tests para comprobar ese código generado, accediendo al resultado del mismo para generar una segunda versión que corrija esos errores? Las posibilidades y posibles estrategias, sumadas a lo que influye la elaboración del prompt en cada caso y modelo, **son infinitas**. A partir de ahí comencé a hacer mis propios experimentos. Por ejemplo, TEAgpt, un sistema diseñado para adaptar un enunciado de una tarea al alumnado TEA, incluso buscando en determinadas fuentes **los pictogramas adecuados** e incorporarlos al documento. También aproveché durante el evento [eurekIA](https://eurekia.es) para explorar con un equipo un sistema al que llamamos MEVALUA. Esta aplicación proporciona retroalimentación al alumnado antes de entregar un trabajo, pudiendo comprobar así que cumple con los requisitos establecidos por el profesorado. Esa retroalimentación incluía comentarios acerca de cómo podía mejorar su entrega, pero nunca indicando la solución concreta, sino animando al estudiante a descubrirla. El objetivo fue conseguir una evaluación formativa realmente efectiva al ser **instantánea y personalizada**. Finalmente, con ánimo de construir algo verdaderamente estable y reutilizable, surgió [Aphra](https://github.com/DavidLMS/aphra). Gracias a este sistema, este blog está disponible **también en inglés**. Si te interesa cómo se ha creado a un nivel más técnico, puedes consultar el [devlog](https://www.linkedin.com/pulse/aphra-devlog-7-en-producción-david-romero-santos-nwp9f).

Haciendo estas pruebas me quedó claro que las interfaces tipo chatbot en las que interactuamos directamente con un modelo de lenguaje en bruto están destinadas a **convertirse en un nicho**. Porque en un sentido práctico no tiene sentido proporcionar continuamente todo el contexto que necesitamos, ni iterar la conversación utilizando una y otra vez las mismas estrategias para llegar al resultado que queremos. No, estos "sistemas complejos" estarán **integrados directamente** en las aplicaciones que utilizamos, en nuestro smartphone, en nuestro sistema operativo. Hasta que el LLM solamente sea **un componente más** del "sistema inteligente".

Quizás estas reflexiones te hayan convencido de que estamos a las puertas de una revolución, o quizás no. Pero hay algo que no he contado. Todas estas "predicciones", por llamarlas de alguna manera, parten de la premisa de que **la tecnología no evolucione**. Es decir, todo esto puede componerse con lo que está inventado hasta ahora. Falta desarrollar muchos sistemas e integrarlos, pero no es necesario un conocimiento nuevo para ello. Sin embargo, cada vez son más fuertes los rumores de que no terminará el año sin que veamos una nueva iteración relevante, una que lleve los LLM a un **nuevo nivel** llamándolos "razonadores". Y esta iteración podrá incorporarse en los "sistemas complejos" ya desarrollados de forma trivial, sustituyendo a los LLM anteriores y desbloqueando una nueva gama completa de posibilidades.

Ahora que comenzamos un nuevo curso, tenemos **una nueva oportunidad** para armarnos, no solo nosotros, sino también a nuestro entorno. A nuestro claustro. A nuestra familia. A nuestras amistades. Solo así reduciremos el número de bajas. Comparte, discute, planifica, conoce, demuestra, anima, persevera. No pierdas la curiosidad y mantén un ojo abierto. Pero no olvides parpadear para hidratarlo. El descanso también es importante, y **muy humano**.

Feliz año nuevo docente.

PD: Ningún modelo de lenguaje ha sido maltratado para la redacción de este artículo... Pero sí para generar la imagen que lo ilustra.